#!/bin/bash
#
# Upload templates and readme files from this repository to an s3 bucket
# This should be run from the directory containing the files you wish to upload
#

# Set some defaults
#+ If you have a variables file it can be used to override these
#+ Options given from the command line always get precidence
S3_BUCKET='nubisproject-stacks'
S3_PATH='master'

# Source the variables file if it exists
#+ Options given from the command line always get precidence
if [ -f "bin/variables" ]; then
    source 'bin/variables'
fi

declare -a FILES_LIST
get_files_list () {
    # Include all markdown files
    FILES=`find ./ -name "*.md" -printf "%f\n"`
    for FILE in $FILES; do
        FILES_LIST=(${FILES_LIST[@]} $FILE)
    done

    # Include all template files
    FILES=`find ./ -name "*.template" -printf "%f\n"`
    for FILE in $FILES; do
        FILES_LIST=(${FILES_LIST[@]} $FILE)
    done
}

push-files () {
    FILE=/path/to/file/to/upload.tar.gz
    echo "Uploading ${#FILES_LIST[@]} files"
    COUNT=1
    for FILE in ${FILES_LIST[@]}; do
        echo "Uploading: $FILE ($COUNT of ${#FILES_LIST[@]})"
        CONTENT_TYPE=`file --brief --mime-type $FILE`
        MD5=`openssl md5 -binary < $FILE | base64`

        # Upload the file
        OUT=$(aws s3api put-object --bucket $S3_BUCKET --content-md5 $MD5 --content-type $CONTENT_TYPE --key ${S3_PATH}/${FILE} --body $FILE 2>&1) 2> /dev/null
        RV=$?
        if [ $RV != 0 ]; then
            echo "ERROR: $OUT"
            exit $RV
        fi

        # Set acl for public read and anyone in this account read / write
        OUT=$(aws s3api put-object-acl --bucket $S3_BUCKET --key ${S3_PATH}/${FILE} --grant-full-control "id=\"$CANONICAL_USER_ID\"" --grant-read 'uri="http://acs.amazonaws.com/groups/global/AllUsers"' 2>&1) 2> /dev/null
        RV=$?
        if [ $RV != 0 ]; then
            echo "ERROR: $OUT"
            exit $RV
        fi
        let COUNT=$COUNT+1
    done
}


# Grab and setup called options
while [ "$1" != "" ]; do
    case $1 in
        -v | --verbose )
            # For this simple script this will basicaly set -x
            set -x
        ;;
        -b | --bucket )
            # The name of a s3 bucket to upload files to
            S3_BUCKET=$2
            shift
        ;;
        -p | --path )
            # The path in the s3 bucket to upload files to
            # This is intended to support versions of these files
            # There should be one path per release
            S3_PATH=$2
            shift
        ;;
        -c | --canonical-user-id )
            # The canonical user id to use in granting r/w priveleges
            #+ to the assets in the s3 bucket
            CANONICAL_USER_ID=$2
            shift
        ;;
         -h | -H | --help )
            echo -en "$0\n\n"
            echo -en "Usage: $0 [options] command\n\n"
            echo -en "Commands:\n"
            echo -en "  push              Push files from the local directory to s3\n"
            echo -en "Options:\n"
            echo -en "  --help      -h    Print this help information and exit\n"
            echo -en "  --bucket    -b    Specify the s3 bucket to upload to\n"
            echo -en "                      Defaults to 'nubisproject-stacks'\n"
            echo -en "  --path      -p    Specify a path to place the files in the s3 bucket\n"
            echo -en "                      Defaults to 'master'\n"
            echo -en "  --verbose   -v    Turn on verbosity\n"
            echo -en "                      Basically set -x\n\n"
            exit 0
        ;;
        push-files | push )
            # This simply grabs everything defined as an output and dumps it.
            # See --file if you wish to save to a file without a redirect
            get_files_list
            push-files
            GOT_COMMAND=1
        ;;
    esac
    shift
done

# If we did not get a valid command print the help message
if [ ${GOT_COMMAND:-0} == 0 ]; then
    $0 --help
fi

exit 0

{
    "Id": "Policy1427394589534",
    "Statement": [
        {
            "Sid": "Stmt1427394583787",
            "Action": "s3:*",
            "Effect": "Allow",
            "Resource": "arn:aws:s3:::nubisproject-stacks/*",
            "Principal": {
                "AWS": [
                    "arn:aws:iam::647505682097:user/jcrowe"
                ]
            }
        }
    ]
}

{
  "Version":"2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1427394583787",
      "Action": "s3:*",
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::nubisproject-stacks/*",
      "Principal": { "AWS": [ "arn:aws:iam::647505682097:user/jcrowe" ] }
    }
  ]
}

{
   "Statement":[
      {
         "Effect":"Allow",
         "Action":[
            "s3:ListAllMyBuckets"
         ],
         "Resource":"arn:aws:s3:::*"
      },
      {
         "Effect":"Allow",
         "Action":[
            "s3:ListBucket",
            "s3:GetBucketLocation"
         ],
         "Resource":"arn:aws:s3:::nubisproject-stacks"
      },
      {
         "Effect":"Allow",
         "Action":[
            "s3:PutObject",
            "s3:GetObject",
            "s3:DeleteObject"
         ],
         "Resource":"arn:aws:s3:::nubisproject-stacks/*"
      }
   ]
}

{
   "Version": "2012-10-17",
   "Statement": [
      {
         "Sid": "statement1",
         "Effect": "Allow",
         "Principal": {
            "AWS": "arn:aws:iam::647505682097:user/jcrowe"
         },
         "Action": [
            "s3:GetBucketLocation",
            "s3:ListBucket"
         ],
         "Resource": [
            "arn:aws:s3:::nubisproject-stacks"
         ]
      },
      {
         "Sid": "statement2",
         "Effect": "Allow",
         "Principal": {
            "AWS": "arn:aws:iam::647505682097:user/jcrowe"
         },
         "Action": [
            "s3:PutObject",
            "s3:GetObject",
            "s3:DeleteObject"
         ],
         "Resource": [
            "arn:aws:s3:::nubisproject-stacks/*"
         ]
      }
   ]
}
